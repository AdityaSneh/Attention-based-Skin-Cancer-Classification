{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5X3ASNLkv3Y",
        "outputId": "93ce14fc-b723-4a0a-9f90-72060d205244"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTi0RAUGEfoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc96303-9e0d-4bb7-d2c0-f96374ec3005"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename=\"/content/drive/My Drive/HAM10000.zip\"\n",
        "with ZipFile(filename,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"done\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa36bMKLze3z"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "import cv2\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers import Layer,InputSpec\r\n",
        "import keras.layers as kl\r\n",
        "from glob import glob\r\n",
        "from sklearn.metrics import roc_curve, auc\r\n",
        "from keras.preprocessing import image\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from tensorflow.keras import callbacks \r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\r\n",
        "from  matplotlib import pyplot as plt\r\n",
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,GlobalAveragePooling2D,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\r\n",
        "%matplotlib inline\r\n",
        "import shutil\r\n",
        "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\r\n",
        "from tensorflow.python.platform import build_info as tf_build_info\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from PIL import ImageFile\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnzRzk7e44HL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1a765338-3750-4803-f650-47c6ea25bef2"
      },
      "source": [
        "data_pd = pd.read_csv('/content/drive/MyDrive/HAM10000_metadata.csv')\r\n",
        "data_pd.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlR6SjeEzXsm"
      },
      "source": [
        "train_dir = os.path.join('HAM10000', 'train_dir')\r\n",
        "test_dir = os.path.join('HAM10000', 'test_dir')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IFqPgUu5jPj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7e18425a-f8e5-47f6-b0cc-49aa3b08878a"
      },
      "source": [
        "# This will tell us how many images are associated with each lesion_id.\r\n",
        "df = data_pd.groupby('lesion_id').count()\r\n",
        "\r\n",
        "# Now we filter out lesion_id's that have only one image associated with it\r\n",
        "df = df[df['image_id'] == 1]\r\n",
        "\r\n",
        "df.reset_index(inplace=True)\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0000004</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0000007</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0000008</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id  image_id  dx  dx_type  age  sex  localization\n",
              "0  HAM_0000001         1   1        1    1    1             1\n",
              "1  HAM_0000003         1   1        1    1    1             1\n",
              "2  HAM_0000004         1   1        1    1    1             1\n",
              "3  HAM_0000007         1   1        1    1    1             1\n",
              "4  HAM_0000008         1   1        1    1    1             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeVfs-Ly95gs"
      },
      "source": [
        "def identify_duplicates(x):\r\n",
        "\r\n",
        "    # Generate a list of items with unique lesion ids from df array.\r\n",
        "    unique_list = list(df['lesion_id'])\r\n",
        "\r\n",
        "    if x in unique_list:\r\n",
        "        return 'no_duplicates'\r\n",
        "    else:\r\n",
        "        return 'has_duplicates'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WZZRSzO5v8t"
      },
      "source": [
        "\r\n",
        "# create a new column that is a copy of the lesion_id column\r\n",
        "data_pd['duplicates'] = data_pd['lesion_id']\r\n",
        "# apply the function to this new column\r\n",
        "data_pd['duplicates'] = data_pd['duplicates'].apply(identify_duplicates)\r\n",
        "\r\n",
        "data_pd.head()\r\n",
        "\r\n",
        "df = data_pd[data_pd['duplicates'] == 'no_duplicates']\r\n",
        "\r\n",
        "# Now we create a test set using df because we are sure that none of these images\r\n",
        "# have augmented duplicates in the train set\r\n",
        "y = df['dx']\r\n",
        "\r\n",
        "_, test_df = train_test_split(df, test_size=0.15, random_state=101, stratify=y)\r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xVuPVd79SbD"
      },
      "source": [
        "# This set will be data_pd excluding all rows that are in the test set\r\n",
        "\r\n",
        "# This function identifies if an image is part of the train\r\n",
        "# or test set.\r\n",
        "def identify_test_rows(x):\r\n",
        "    # create a list of all the lesion_id's in the test set\r\n",
        "    test_list = list(test_df['image_id'])\r\n",
        "\r\n",
        "    if str(x) in test_list:\r\n",
        "        return 'test'\r\n",
        "    else:\r\n",
        "        return 'train'\r\n",
        "\r\n",
        "\r\n",
        "# Copy image_id column to train_or_test column.\r\n",
        "data_pd['train_or_test'] = data_pd['image_id']\r\n",
        "\r\n",
        "\r\n",
        "# Apply identify_test_rows to this copied column.     \r\n",
        "data_pd['train_or_test'] = data_pd['train_or_test'].apply(identify_test_rows)\r\n",
        "\r\n",
        "\r\n",
        "# Add data that is part of the training dataset by using applied function and taking result.\r\n",
        "train_df = data_pd[data_pd['train_or_test'] == 'train']\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Get a list of train and test images\r\n",
        "train_list = list(train_df['image_id'])\r\n",
        "test_list = list(test_df['image_id'])\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEChk1DK-H8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b591c7a-490d-40fe-8b03-3b8ab9fba2c3"
      },
      "source": [
        "len(train_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIoMqylGAYYZ"
      },
      "source": [
        "# Set the image_id as the index in data_pd\r\n",
        "data_pd.set_index('image_id', inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja_PtDYyDPMM"
      },
      "source": [
        "os.mkdir(train_dir)\r\n",
        "os.mkdir(test_dir)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsoqCvNsgmHP"
      },
      "source": [
        "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KYMTQugCmRR"
      },
      "source": [
        "for i in targetnames:\r\n",
        "  directory1=train_dir+'/'+i\r\n",
        "  directory2=test_dir+'/'+i\r\n",
        "  os.mkdir(directory1)\r\n",
        "  os.mkdir(directory2)\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL9vFa3X-ty1"
      },
      "source": [
        "for image in train_list:\r\n",
        "\r\n",
        "    file_name = image+'.jpg'\r\n",
        "    label = data_pd.loc[image, 'dx']\r\n",
        "\r\n",
        "\r\n",
        "    # destination path to image\r\n",
        "    source = os.path.join('HAM10000', file_name)\r\n",
        "\r\n",
        "    # copy the image from the source to the destination\r\n",
        "    dest = os.path.join(train_dir, label, file_name)\r\n",
        "\r\n",
        "    shutil.copyfile(source, dest)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwbKrEzJ_if2"
      },
      "source": [
        "\r\n",
        "for image in test_list:\r\n",
        "\r\n",
        "    # Set all file names as name + jpeg extension.\r\n",
        "    file_name = image+'.jpg'\r\n",
        "    label = data_pd.loc[image, 'dx']\r\n",
        "\r\n",
        "    # destination path to image\r\n",
        "    source = os.path.join('HAM10000', file_name)\r\n",
        "\r\n",
        "    # copy the image from the source to the destination\r\n",
        "    dest = os.path.join(test_dir, label, file_name)\r\n",
        "\r\n",
        "    shutil.copyfile(source, dest)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W8hmE2OHjQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10546cd0-6b75-4acf-b68a-0c49a6084f3e"
      },
      "source": [
        "\r\n",
        "\r\n",
        "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\r\n",
        "\r\n",
        "# Create an augmented dataset which will expand the dataset of all image\r\n",
        "# classes.\r\n",
        "for item in targetnames:\r\n",
        "\r\n",
        "    # We are creating temporary directories here because we delete these directories later\r\n",
        "    # create a base dir\r\n",
        "    aug_dir = 'aug_dir'\r\n",
        "    os.mkdir(aug_dir)\r\n",
        "    # create a dir within the base dir to store images of the same class\r\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\r\n",
        "    os.mkdir(img_dir)\r\n",
        "\r\n",
        "    # Get class from class_list array. Represents respective file in HAM10000 dir.\r\n",
        "    img_class = item\r\n",
        "\r\n",
        "    # list all images in that directory\r\n",
        "    img_list = os.listdir('HAM10000/train_dir/' + img_class)\r\n",
        "\r\n",
        "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\r\n",
        "    for file_name in img_list:\r\n",
        "\r\n",
        "        # Create source directory which is in training directory.\r\n",
        "        src = os.path.join('HAM10000/train_dir/' + img_class, file_name)\r\n",
        "\r\n",
        "        # Create destination folder which is in image directory.\r\n",
        "        dst = os.path.join(img_dir, file_name)\r\n",
        "\r\n",
        "        # Copy all images from src -> dst folder.\r\n",
        "        shutil.copyfile(src, dst)\r\n",
        "\r\n",
        "    # Temporary augumented dataset directory, will be deleted upon training.\r\n",
        "    path = aug_dir\r\n",
        "\r\n",
        "    # Set our save path to training directory for all augmented imgs produced.\r\n",
        "    save_path = 'HAM10000/train_dir/' + img_class\r\n",
        "\r\n",
        "    # Create Datagen generator.\r\n",
        "    # We will be using an ImageDataGenerator because we are processing\r\n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
        "\r\n",
        "        rotation_range=180,\r\n",
        "        width_shift_range=0.1,\r\n",
        "        height_shift_range=0.1,\r\n",
        "        zoom_range=0.1,\r\n",
        "        horizontal_flip=True,\r\n",
        "        vertical_flip=True,\r\n",
        "        fill_mode='nearest'\r\n",
        "\r\n",
        "    )\r\n",
        "\r\n",
        "    batch_size = 50\r\n",
        "\r\n",
        "    aug_datagen = datagen.flow_from_directory(path,save_to_dir=save_path,save_format='jpg',target_size=(224, 224),batch_size=batch_size)\r\n",
        "\r\n",
        "    # Generate the augmented images and add them to the training folders\r\n",
        "    num_aug_images_wanted = 8000  # total number of images we want to have in each class\r\n",
        "\r\n",
        "    num_files = len(os.listdir(img_dir))\r\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted - num_files) / batch_size))\r\n",
        "\r\n",
        "    # run the generator and create about 8000 augmented images\r\n",
        "    for i in range(0, num_batches):\r\n",
        "        images, labels = next(aug_datagen)\r\n",
        "\r\n",
        "    # delete temporary directory with the raw image files\r\n",
        "    shutil.rmtree('aug_dir')\r\n",
        "\r\n",
        "    # End for loop\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 304 images belonging to 1 classes.\n",
            "Found 488 images belonging to 1 classes.\n",
            "Found 1033 images belonging to 1 classes.\n",
            "Found 109 images belonging to 1 classes.\n",
            "Found 1079 images belonging to 1 classes.\n",
            "Found 6042 images belonging to 1 classes.\n",
            "Found 132 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNisha_gM3_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5df950b-34eb-4f7b-ecb6-7885c55660a4"
      },
      "source": [
        "\r\n",
        "# BUILD MODEL\r\n",
        "\r\n",
        "train_path = 'HAM10000/train_dir'\r\n",
        "test_path = 'HAM10000/test_dir'\r\n",
        "\r\n",
        "train_samples = len(train_df)\r\n",
        "test_samples = len(test_df)\r\n",
        "\r\n",
        "train_batch_size = 10\r\n",
        "test_batch_size = 10\r\n",
        "image_size = 224\r\n",
        "\r\n",
        "# Divide total # of samples by batch size to section off training samples into steps.\r\n",
        "# Then round up with np.ceil function.\r\n",
        "train_steps = np.ceil(train_samples / train_batch_size)\r\n",
        "test_steps = np.ceil(test_samples / test_batch_size)\r\n",
        "\r\n",
        "# Create an Image Data Generator to input later into our model.\r\n",
        "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\r\n",
        "\r\n",
        "\r\n",
        "### GETTING BATCHES FROM DIRECTORY PATHS ###\r\n",
        "print(\"\\nTrain Batches: \")\r\n",
        "train_batches = datagen.flow_from_directory(directory=train_path,\r\n",
        "                                            target_size=(image_size,image_size),\r\n",
        "                                            batch_size=train_batch_size,\r\n",
        "                                            shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"\\nTest Batches: \")\r\n",
        "test_batches =datagen.flow_from_directory(test_path,\r\n",
        "                                           target_size=(image_size,image_size),\r\n",
        "                                           batch_size=1,\r\n",
        "                                           shuffle=False)\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Batches: \n",
            "Found 51699 images belonging to 7 classes.\n",
            "\n",
            "Test Batches: \n",
            "Found 828 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbwfHcsOPKYB"
      },
      "source": [
        "#Soft Attention\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer,InputSpec\n",
        "import keras.layers as kl\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class SoftAttention(Layer):\n",
        "    def __init__(self,ch,m,concat_with_x=False,aggregate=False,**kwargs):\n",
        "        self.channels=int(ch)\n",
        "        self.multiheads = m\n",
        "        self.aggregate_channels = aggregate\n",
        "        self.concat_input_with_scaled = concat_with_x\n",
        "\n",
        "        \n",
        "        super(SoftAttention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "\n",
        "        self.i_shape = input_shape\n",
        "\n",
        "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
        "    \n",
        "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
        "        \n",
        "        if self.aggregate_channels==False:\n",
        "\n",
        "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
        "        else:\n",
        "            if self.concat_input_with_scaled:\n",
        "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
        "            else:\n",
        "                self.out_features_shape = input_shape\n",
        "        \n",
        "\n",
        "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
        "                                        initializer='he_uniform',\n",
        "                                        name='kernel_conv3d')\n",
        "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
        "                                      initializer='zeros',\n",
        "                                      name='bias_conv3d')\n",
        "\n",
        "        super(SoftAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        exp_x = K.expand_dims(x,axis=-1)\n",
        "\n",
        "        c3d = K.conv3d(exp_x,\n",
        "                     kernel=self.kernel_conv3d,\n",
        "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
        "        conv3d = K.bias_add(c3d,\n",
        "                        self.bias_conv3d)\n",
        "        conv3d = kl.Activation('relu')(conv3d)\n",
        "\n",
        "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
        "\n",
        "        \n",
        "        conv3d = K.squeeze(conv3d, axis=-1)\n",
        "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
        "\n",
        "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
        "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
        "\n",
        "        \n",
        "        if self.aggregate_channels==False:\n",
        "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
        "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
        "   \n",
        "            x_exp = K.expand_dims(x,axis=-2)\n",
        "   \n",
        "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
        "  \n",
        "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
        "\n",
        "        else:\n",
        "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
        "\n",
        "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
        "\n",
        "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
        "\n",
        "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
        "\n",
        "        if self.concat_input_with_scaled:\n",
        "            o = kl.Concatenate(axis=-1)([u,x])\n",
        "        else:\n",
        "            o = u\n",
        "        \n",
        "        return [o, softmax_alpha]\n",
        "\n",
        "    def compute_output_shape(self, input_shape): \n",
        "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
        "\n",
        "    \n",
        "    def get_config(self):\n",
        "        return super(SoftAttention,self).get_config()\n",
        " "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrlJwba5By1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1735d18d-bc75-472c-b83d-1a2bb050d853"
      },
      "source": [
        "resnet = tf.keras.applications.ResNet50(\r\n",
        "    include_top=True,\r\n",
        "    weights=\"imagenet\",\r\n",
        "    input_tensor=None,\r\n",
        "    input_shape=None,\r\n",
        "    pooling=None,\r\n",
        "    classes=1000,\r\n",
        ")\r\n",
        "\r\n",
        "# Exclude the last 3 layers of the model.\r\n",
        "conv = resnet.layers[-3].output"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R13YR5JxVpOg"
      },
      "source": [
        "\r\n",
        "output = GlobalAveragePooling2D()(conv)\r\n",
        "output = Dense(7, activation='softmax')(output)\r\n",
        "model = Model(inputs=resnet.input, outputs=output)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD2GGKGNV23W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd97c665-9eef-4165-ec1a-8c6a7f0392ab"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            14343       global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 23,602,055\n",
            "Trainable params: 23,548,935\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR0fUpy18vAZ"
      },
      "source": [
        "opt1=tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=0.1)\r\n",
        "model.compile(optimizer=opt1,\r\n",
        "             loss='categorical_crossentropy',\r\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAf5ha295reS"
      },
      "source": [
        "class_weights = {   \r\n",
        "                    0: 1.0,  # akiec\r\n",
        "                    1: 1.0,  # bcc\r\n",
        "                    2: 1.0,  # bkl\r\n",
        "                    3: 1.0,  # df\r\n",
        "                    4: 5.0,  # mel\r\n",
        "                    5: 1.0,  # nv\r\n",
        "                    6: 1.0,  # vasc\r\n",
        "                }\r\n",
        "\r\n",
        "\r\n",
        "checkpoint=  ModelCheckpoint(filepath = 'ResNet50.hdf5',monitor='val_accuracy',save_best_only=True,save_weights_only=True)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUzTmiZ-8hL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46eeb3e9-4356-45d4-910e-1532766e318a"
      },
      "source": [
        "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=40, min_delta=0.001)\r\n",
        "history = model.fit(train_batches,\r\n",
        "                    steps_per_epoch=train_steps,\r\n",
        "                    epochs=300,\r\n",
        "                    verbose=2,\r\n",
        "                    validation_data=test_batches,validation_steps=len(test_df),callbacks=[checkpoint,Earlystop],class_weight=class_weights)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "919/919 - 85s - loss: 1.9275 - accuracy: 0.4376 - val_loss: 0.8518 - val_accuracy: 0.8080\n",
            "Epoch 2/300\n",
            "919/919 - 76s - loss: 1.5601 - accuracy: 0.5326 - val_loss: 0.7295 - val_accuracy: 0.7657\n",
            "Epoch 3/300\n",
            "919/919 - 76s - loss: 1.3781 - accuracy: 0.5890 - val_loss: 0.4901 - val_accuracy: 0.8442\n",
            "Epoch 4/300\n",
            "919/919 - 76s - loss: 1.2963 - accuracy: 0.6118 - val_loss: 0.4910 - val_accuracy: 0.8382\n",
            "Epoch 5/300\n",
            "919/919 - 76s - loss: 1.1731 - accuracy: 0.6502 - val_loss: 0.6289 - val_accuracy: 0.8031\n",
            "Epoch 6/300\n",
            "919/919 - 76s - loss: 1.0880 - accuracy: 0.6729 - val_loss: 0.4986 - val_accuracy: 0.8309\n",
            "Epoch 7/300\n",
            "919/919 - 76s - loss: 1.0301 - accuracy: 0.6900 - val_loss: 0.7125 - val_accuracy: 0.7367\n",
            "Epoch 8/300\n",
            "919/919 - 76s - loss: 0.9887 - accuracy: 0.7017 - val_loss: 0.6859 - val_accuracy: 0.8140\n",
            "Epoch 9/300\n",
            "919/919 - 76s - loss: 0.9602 - accuracy: 0.7201 - val_loss: 0.7569 - val_accuracy: 0.7307\n",
            "Epoch 10/300\n",
            "919/919 - 76s - loss: 0.9136 - accuracy: 0.7293 - val_loss: 0.3537 - val_accuracy: 0.8804\n",
            "Epoch 11/300\n",
            "919/919 - 76s - loss: 0.8196 - accuracy: 0.7612 - val_loss: 0.5892 - val_accuracy: 0.7633\n",
            "Epoch 12/300\n",
            "919/919 - 76s - loss: 0.8002 - accuracy: 0.7667 - val_loss: 1.0892 - val_accuracy: 0.6824\n",
            "Epoch 13/300\n",
            "919/919 - 76s - loss: 0.7286 - accuracy: 0.7792 - val_loss: 0.4790 - val_accuracy: 0.8345\n",
            "Epoch 14/300\n",
            "919/919 - 76s - loss: 0.7169 - accuracy: 0.7918 - val_loss: 0.5911 - val_accuracy: 0.7995\n",
            "Epoch 15/300\n",
            "919/919 - 76s - loss: 0.6724 - accuracy: 0.7979 - val_loss: 0.3841 - val_accuracy: 0.8671\n",
            "Epoch 16/300\n",
            "919/919 - 76s - loss: 0.6547 - accuracy: 0.8085 - val_loss: 0.5132 - val_accuracy: 0.8309\n",
            "Epoch 17/300\n",
            "919/919 - 76s - loss: 0.5916 - accuracy: 0.8243 - val_loss: 0.4008 - val_accuracy: 0.8732\n",
            "Epoch 18/300\n",
            "919/919 - 76s - loss: 0.5977 - accuracy: 0.8292 - val_loss: 0.5063 - val_accuracy: 0.8780\n",
            "Epoch 19/300\n",
            "919/919 - 76s - loss: 0.5670 - accuracy: 0.8305 - val_loss: 0.4025 - val_accuracy: 0.8756\n",
            "Epoch 20/300\n",
            "919/919 - 76s - loss: 0.5404 - accuracy: 0.8421 - val_loss: 0.3691 - val_accuracy: 0.8816\n",
            "Epoch 21/300\n",
            "919/919 - 76s - loss: 0.5324 - accuracy: 0.8466 - val_loss: 0.5269 - val_accuracy: 0.8200\n",
            "Epoch 22/300\n",
            "919/919 - 76s - loss: 0.4979 - accuracy: 0.8597 - val_loss: 0.3161 - val_accuracy: 0.8901\n",
            "Epoch 23/300\n",
            "919/919 - 76s - loss: 0.4687 - accuracy: 0.8663 - val_loss: 0.5691 - val_accuracy: 0.8454\n",
            "Epoch 24/300\n",
            "919/919 - 76s - loss: 0.4413 - accuracy: 0.8725 - val_loss: 0.4284 - val_accuracy: 0.8756\n",
            "Epoch 25/300\n",
            "919/919 - 76s - loss: 0.4369 - accuracy: 0.8742 - val_loss: 0.4001 - val_accuracy: 0.8853\n",
            "Epoch 26/300\n",
            "919/919 - 76s - loss: 0.4520 - accuracy: 0.8677 - val_loss: 0.3544 - val_accuracy: 0.8913\n",
            "Epoch 27/300\n",
            "919/919 - 76s - loss: 0.3922 - accuracy: 0.8893 - val_loss: 0.4094 - val_accuracy: 0.8575\n",
            "Epoch 28/300\n",
            "919/919 - 76s - loss: 0.3846 - accuracy: 0.8873 - val_loss: 0.3696 - val_accuracy: 0.8865\n",
            "Epoch 29/300\n",
            "919/919 - 76s - loss: 0.3489 - accuracy: 0.8982 - val_loss: 0.4112 - val_accuracy: 0.8768\n",
            "Epoch 30/300\n",
            "919/919 - 76s - loss: 0.3755 - accuracy: 0.8979 - val_loss: 0.4873 - val_accuracy: 0.8599\n",
            "Epoch 31/300\n",
            "919/919 - 76s - loss: 0.3459 - accuracy: 0.9024 - val_loss: 0.3593 - val_accuracy: 0.8865\n",
            "Epoch 32/300\n",
            "919/919 - 76s - loss: 0.2950 - accuracy: 0.9184 - val_loss: 0.3984 - val_accuracy: 0.8780\n",
            "Epoch 33/300\n",
            "919/919 - 76s - loss: 0.3141 - accuracy: 0.9098 - val_loss: 0.5002 - val_accuracy: 0.8514\n",
            "Epoch 34/300\n",
            "919/919 - 76s - loss: 0.2868 - accuracy: 0.9195 - val_loss: 0.4435 - val_accuracy: 0.8671\n",
            "Epoch 35/300\n",
            "919/919 - 76s - loss: 0.2847 - accuracy: 0.9209 - val_loss: 0.6051 - val_accuracy: 0.8116\n",
            "Epoch 36/300\n",
            "919/919 - 76s - loss: 0.2919 - accuracy: 0.9215 - val_loss: 0.4902 - val_accuracy: 0.8804\n",
            "Epoch 37/300\n",
            "919/919 - 76s - loss: 0.2632 - accuracy: 0.9232 - val_loss: 0.3950 - val_accuracy: 0.8853\n",
            "Epoch 38/300\n",
            "919/919 - 76s - loss: 0.2383 - accuracy: 0.9325 - val_loss: 0.3550 - val_accuracy: 0.9010\n",
            "Epoch 39/300\n",
            "919/919 - 76s - loss: 0.2070 - accuracy: 0.9427 - val_loss: 0.3857 - val_accuracy: 0.8853\n",
            "Epoch 40/300\n",
            "919/919 - 76s - loss: 0.2382 - accuracy: 0.9313 - val_loss: 0.5664 - val_accuracy: 0.8587\n",
            "Epoch 41/300\n",
            "919/919 - 76s - loss: 0.2393 - accuracy: 0.9311 - val_loss: 0.3923 - val_accuracy: 0.8937\n",
            "Epoch 42/300\n",
            "919/919 - 76s - loss: 0.2427 - accuracy: 0.9312 - val_loss: 0.4936 - val_accuracy: 0.8720\n",
            "Epoch 43/300\n",
            "919/919 - 76s - loss: 0.2032 - accuracy: 0.9437 - val_loss: 0.4862 - val_accuracy: 0.8792\n",
            "Epoch 44/300\n",
            "919/919 - 76s - loss: 0.1957 - accuracy: 0.9464 - val_loss: 0.4224 - val_accuracy: 0.8865\n",
            "Epoch 45/300\n",
            "919/919 - 76s - loss: 0.1693 - accuracy: 0.9502 - val_loss: 0.3690 - val_accuracy: 0.9010\n",
            "Epoch 46/300\n",
            "919/919 - 75s - loss: 0.1984 - accuracy: 0.9470 - val_loss: 0.4261 - val_accuracy: 0.8732\n",
            "Epoch 47/300\n",
            "919/919 - 76s - loss: 0.1789 - accuracy: 0.9506 - val_loss: 0.4152 - val_accuracy: 0.8877\n",
            "Epoch 48/300\n",
            "919/919 - 75s - loss: 0.1850 - accuracy: 0.9448 - val_loss: 0.4702 - val_accuracy: 0.8684\n",
            "Epoch 49/300\n",
            "919/919 - 76s - loss: 0.2091 - accuracy: 0.9425 - val_loss: 0.4805 - val_accuracy: 0.8816\n",
            "Epoch 50/300\n",
            "919/919 - 75s - loss: 0.1465 - accuracy: 0.9576 - val_loss: 0.3554 - val_accuracy: 0.8925\n",
            "Epoch 51/300\n",
            "919/919 - 75s - loss: 0.1233 - accuracy: 0.9644 - val_loss: 0.3589 - val_accuracy: 0.9046\n",
            "Epoch 52/300\n",
            "919/919 - 76s - loss: 0.1752 - accuracy: 0.9533 - val_loss: 0.5407 - val_accuracy: 0.8647\n",
            "Epoch 53/300\n",
            "919/919 - 75s - loss: 0.1588 - accuracy: 0.9547 - val_loss: 0.4752 - val_accuracy: 0.8877\n",
            "Epoch 54/300\n",
            "919/919 - 75s - loss: 0.1630 - accuracy: 0.9557 - val_loss: 0.4127 - val_accuracy: 0.8768\n",
            "Epoch 55/300\n",
            "919/919 - 75s - loss: 0.1291 - accuracy: 0.9629 - val_loss: 0.4526 - val_accuracy: 0.8756\n",
            "Epoch 56/300\n",
            "919/919 - 75s - loss: 0.1346 - accuracy: 0.9646 - val_loss: 0.3672 - val_accuracy: 0.8986\n",
            "Epoch 57/300\n",
            "919/919 - 75s - loss: 0.1012 - accuracy: 0.9728 - val_loss: 0.4221 - val_accuracy: 0.8889\n",
            "Epoch 58/300\n",
            "919/919 - 75s - loss: 0.1223 - accuracy: 0.9665 - val_loss: 0.4261 - val_accuracy: 0.8949\n",
            "Epoch 59/300\n",
            "919/919 - 75s - loss: 0.1192 - accuracy: 0.9680 - val_loss: 0.3998 - val_accuracy: 0.8973\n",
            "Epoch 60/300\n",
            "919/919 - 75s - loss: 0.1133 - accuracy: 0.9670 - val_loss: 0.3703 - val_accuracy: 0.8925\n",
            "Epoch 61/300\n",
            "919/919 - 76s - loss: 0.1180 - accuracy: 0.9671 - val_loss: 0.3700 - val_accuracy: 0.8877\n",
            "Epoch 62/300\n",
            "919/919 - 75s - loss: 0.0983 - accuracy: 0.9730 - val_loss: 0.3756 - val_accuracy: 0.8986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm_AewFBXTj8"
      },
      "source": [
        "from tensorflow.keras import models\r\n",
        "model.load_weights(\"ResNet50.hdf5\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO8IxF0er88T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06213eb5-1cb3-4711-eb54-15bef8ae1f31"
      },
      "source": [
        "predictions = model.predict(test_batches, steps=len(test_df), verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "828/828 [==============================] - 9s 10ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYxCDDjusR-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c8e9d3-d9d3-4880-d26a-91414471fb64"
      },
      "source": [
        "\r\n",
        "y_pred = np.argmax(predictions, axis=1)\r\n",
        "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\r\n",
        "# Get the labels of the test images.\r\n",
        "y_true = test_batches.classes\r\n",
        "y_prob=predictions\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "y_test = to_categorical(y_true)\r\n",
        "\r\n",
        "# Create classification report with matrix labels and target names.\r\n",
        "report = classification_report(y_true, y_pred, target_names=targetnames)\r\n",
        "\r\n",
        "print(\"\\nClassification Report:\")\r\n",
        "print(report)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.74      0.74      0.74        23\n",
            "         bcc       0.91      0.77      0.83        26\n",
            "         bkl       0.67      0.50      0.57        66\n",
            "          df       0.80      0.67      0.73         6\n",
            "         mel       0.52      0.50      0.51        34\n",
            "          nv       0.95      0.98      0.96       663\n",
            "        vasc       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.90       828\n",
            "   macro avg       0.78      0.72      0.75       828\n",
            "weighted avg       0.90      0.90      0.90       828\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy59Zs1jqylz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48925225-2fa5-4ed6-9439-6ae2adef1b6a"
      },
      "source": [
        "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\r\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\r\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\r\n",
        "print(\"weighted Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='weighted')))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.8981171733390011\n",
            "Recall: 0.9045893719806763\n",
            "Accuracy: 0.9045893719806763\n",
            "weighted Roc score: 0.9727752250647581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFRWOB82sDKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2813e781-55a8-4203-8ef0-7b94ca628e30"
      },
      "source": [
        "\r\n",
        "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\r\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\r\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\r\n",
        "print(\"Macro Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='macro')))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.7832723409602609\n",
            "Recall: 0.7219873902738353\n",
            "Accuracy: 0.9045893719806763\n",
            "Macro Roc score: 0.9758549231296252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDNAPv9OsRVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1d443e-020a-4af0-b8ad-01f2fcd7f20a"
      },
      "source": [
        "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\r\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\r\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\r\n",
        "tpr={}\r\n",
        "fpr={}\r\n",
        "roc_auc={}\r\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_prob.ravel())\r\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
        "print(\"Micro Roc score: \" + str(roc_auc[\"micro\"]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9045893719806763\n",
            "Recall: 0.9045893719806763\n",
            "Accuracy: 0.9045893719806763\n",
            "Micro Roc score: 0.9931541333131073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U03sRDM2sudx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235ea641-5f7c-421e-cfa5-e27b99ad0eb8"
      },
      "source": [
        "fpr = {}\r\n",
        "tpr = {}\r\n",
        "roc_auc = {}\r\n",
        "for i in range(7):\r\n",
        "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\r\n",
        "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The ROC AUC score of akiec is: 0.9808263570078315\n",
            "The ROC AUC score of bcc is: 0.9974582773834644\n",
            "The ROC AUC score of bkl is: 0.94887854927225\n",
            "The ROC AUC score of df is: 0.97323600973236\n",
            "The ROC AUC score of mel is: 0.9610683064157653\n",
            "The ROC AUC score of nv is: 0.9741624388683212\n",
            "The ROC AUC score of vasc is: 0.9953545232273838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5nG-b11wkep"
      },
      "source": [
        "# Compute ROC curve and ROC area for each class\r\n",
        "fpr = {}\r\n",
        "tpr = {}\r\n",
        "roc_auc = dict()\r\n",
        "for i in range(7):\r\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)\r\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wz2--WDwHQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4f5ef06b-8812-4a4f-ac8f-53041987d159"
      },
      "source": [
        "\r\n",
        "plt.plot(fpr[0], tpr[0],'v-',label='akiec: ROC curve of (area = %0.2f)' % roc_auc[0])\r\n",
        "plt.plot(fpr[1], tpr[1],'c',label='bcc: ROC curve of (area = %0.2f)' % roc_auc[1])\r\n",
        "plt.plot(fpr[2], tpr[2],'b',label='bkl: ROC curve of (area = %0.2f)' % roc_auc[2])\r\n",
        "plt.plot(fpr[3], tpr[3],'g',label='df: ROC curve of (area = %0.2f)' % roc_auc[3])\r\n",
        "plt.plot(fpr[4], tpr[4],'y',label='mel: ROC curve of (area = %0.2f)' % roc_auc[4])\r\n",
        "plt.plot(fpr[5], tpr[5],'o-',label='nv: ROC curve of (area = %0.2f)' % roc_auc[5])\r\n",
        "plt.plot(fpr[6], tpr[6],'r',label='vasc: ROC curve of (area = %0.2f)' % roc_auc[6])\r\n",
        "\r\n",
        "plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "plt.xlim([-0.1, 1.1])\r\n",
        "plt.ylim([-0.1, 1.1])\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.title('Receiver operating characteristic of %s'%targetnames[i])\r\n",
        "plt.legend(loc=\"lower right\")\r\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}